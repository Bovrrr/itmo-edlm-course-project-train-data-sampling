{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8822f805-0356-4456-b94f-a408d67d9ae2",
   "metadata": {},
   "source": [
    "# 1 — Full determinism + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad1759e-2911-476e-a281-c6c979bea243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic init done.\n"
     ]
    }
   ],
   "source": [
    "# --- FULL DETERMINISM BLOCK ---\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"FLASH_ATTENTION_USE_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/onbaev.baurzhan/source/project/src\")\n",
    "\n",
    "print(\"Deterministic init done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b4189-981e-4e6e-9d8e-454f1e84c3ac",
   "metadata": {},
   "source": [
    "# 2 — Загрузка SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17febe5c-4a7c-4ddb-895b-22c0a54668d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onbaev.baurzhan/source/project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67349, 872)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"glue\", \"sst2\")\n",
    "train_raw = ds[\"train\"]\n",
    "val_raw   = ds[\"validation\"]\n",
    "\n",
    "len(train_raw), len(val_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df16a6-9cfe-479d-8f6c-1e6e921d7153",
   "metadata": {},
   "source": [
    "# 3 — Токенизация (нужна полная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e57cffff-fc6c-4c2b-90e7-7c51f753ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67349, 872)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    enc[\"label\"] = batch[\"label\"]\n",
    "    return enc\n",
    "\n",
    "train_tok_full = train_raw.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    remove_columns=train_raw.column_names\n",
    ")\n",
    "\n",
    "val_tok = val_raw.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    remove_columns=val_raw.column_names\n",
    ")\n",
    "\n",
    "len(train_tok_full), len(val_tok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79be5c9-411b-4441-8e07-bbaf47188d07",
   "metadata": {},
   "source": [
    "# 4 — Формируем начальное seed-подмножество 5% Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd94a959-9433-475a-a1b2-e42f34840d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_total = len(train_raw)\n",
    "k5 = int(0.05 * N_total)\n",
    "\n",
    "random_5 = train_raw.shuffle(seed=42).select(range(k5))\n",
    "\n",
    "train_tok_5 = random_5.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    remove_columns=random_5.column_names\n",
    ")\n",
    "\n",
    "len(train_tok_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f6a90-31ef-45b4-86ca-b5de50142324",
   "metadata": {},
   "source": [
    "# 5 — Обучаем seed-модель на 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee143997-69d4-47b9-bd52-871786dbbc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/onbaev.baurzhan/source/project/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:468.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "train_loss: 0.4792222325813095\n",
      "{'val_loss': 0.2882754536611693, 'accuracy': 0.8727064220183486, 'f1': 0.8762541806020067}\n",
      "\n",
      "Epoch 2\n",
      "train_loss: 0.21002090205702018\n",
      "{'val_loss': 0.24003498894827707, 'accuracy': 0.9128440366972477, 'f1': 0.9138321995464853}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.24003498894827707,\n",
       " 'accuracy': 0.9128440366972477,\n",
       " 'f1': 0.9138321995464853}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_utils import train_model\n",
    "\n",
    "seed_model, seed_metrics = train_model(\n",
    "    model_name=model_name,\n",
    "    train_dataset=train_tok_5,\n",
    "    val_dataset=val_tok,\n",
    "    epochs=2,\n",
    "    lr=2e-5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "seed_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc3ae27-980c-4fe8-90c4-d784068e0cbb",
   "metadata": {},
   "source": [
    "# 6 — DataLoader для скоринга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c699803d-e9db-4435-9bc8-4bc12559070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "def make_loader_for_scoring(dataset, batch_size=64):\n",
    "    def collate_fn(batch):\n",
    "        enc = tokenizer.pad(\n",
    "            {\n",
    "                \"input_ids\": [x[\"input_ids\"] for x in batch],\n",
    "                \"attention_mask\": [x[\"attention_mask\"] for x in batch],\n",
    "            },\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = torch.tensor([x[\"label\"] for x in batch], dtype=torch.long)\n",
    "        enc[\"labels\"] = labels\n",
    "        return enc\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "scoring_loader = make_loader_for_scoring(train_tok_full, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed36e7-a12f-4157-b8c4-4e27f66cae8f",
   "metadata": {},
   "source": [
    "# 7 — Считаем p_gold для каждого примера полного train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4b2b96-0556-4353-a0d5-fdd80c5a4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "p_gold_list = []   # (idx, p_gold)\n",
    "\n",
    "seed_model.eval()\n",
    "seed_model.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    global_idx = 0\n",
    "    for batch in scoring_loader:\n",
    "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "\n",
    "        logits = seed_model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"]\n",
    "        ).logits\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            y = labels[i].item()\n",
    "            p = probs[i, y].item()\n",
    "            p_gold_list.append((global_idx, p))\n",
    "            global_idx += 1\n",
    "\n",
    "len(p_gold_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c815fb7-8bdc-4fd4-93a7-348585e4f717",
   "metadata": {},
   "source": [
    "# 8 — Убираем уже выбранные random 5% из поиска hard-примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb136c1e-9d54-4268-9c46-6db251789db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63982"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_5_indices = set(random_5[\"idx\"] if \"idx\" in random_5.column_names else random_5.indices)\n",
    "# datasets не всегда хранят индексы → используем позиционные\n",
    "random_5_indices = set(range(k5))\n",
    "\n",
    "# оставшиеся 95%\n",
    "remaining = [(i, p) for (i, p) in p_gold_list if i not in random_5_indices]\n",
    "len(remaining)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdde33a-3905-4018-828a-89f60d442324",
   "metadata": {},
   "source": [
    "# 9 — Выбираем bottom-5% hard примеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22414d48-f4b5-4aa6-8586-42ff78abe935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, [41765, 23459, 37621, 46803, 36193, 7250, 60289, 52758, 53313, 63212])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k5_hard = k5  # ещё 5%\n",
    "\n",
    "remaining_sorted = sorted(remaining, key=lambda x: x[1])  # low → first\n",
    "hard_indices = [idx for idx, _ in remaining_sorted[:k5_hard]]\n",
    "\n",
    "len(hard_indices), hard_indices[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d32ae3-c6e1-47b7-a0c8-51e8d33e0bc6",
   "metadata": {},
   "source": [
    "# 10 — Формируем финальные 10% (5% Random + 5% Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59456da4-9d35-4e4f-8d4f-96849515e71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6734"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_indices = list(random_5_indices) + hard_indices\n",
    "len(final_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05852381-a2a1-48f4-bd38-5dca6ea6bf83",
   "metadata": {},
   "source": [
    "# 11 — Собираем финальный токенизированный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b316a60-bd0f-40c9-ad7d-58bfac1a3cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6734"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok_final = train_tok_full.select(final_indices)\n",
    "len(train_tok_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b194031-881b-4876-bb42-6e00369c2295",
   "metadata": {},
   "source": [
    "# 12 — Финальное обучение модели на гибридном поднаборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23af7b79-19ba-4ee8-bf32-127d819cd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "W1122 08:09:51.314000 140462576725056 torch/_dynamo/convert_frame.py:357] torch._dynamo hit config.accumulated_cache_size_limit (64)\n",
      "W1122 08:09:51.314000 140462576725056 torch/_dynamo/convert_frame.py:357]    function: 'compiled_mlp' (/home/onbaev.baurzhan/source/project/.venv/lib/python3.11/site-packages/transformers/models/modernbert/modeling_modernbert.py:528)\n",
      "W1122 08:09:51.314000 140462576725056 torch/_dynamo/convert_frame.py:357]    last reason: ___check_obj_id(L['self'], 140461664635856)                 \n",
      "W1122 08:09:51.314000 140462576725056 torch/_dynamo/convert_frame.py:357] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1122 08:09:51.314000 140462576725056 torch/_dynamo/convert_frame.py:357] To diagnose recompilation issues, see https://pytorch.org/docs/master/compile/troubleshooting.html.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "train_loss: 0.6760260202873375\n",
      "{'val_loss': 0.5957657120057515, 'accuracy': 0.6857798165137615, 'f1': 0.5823170731707317}\n",
      "\n",
      "Epoch 2\n",
      "train_loss: 0.533841029445142\n",
      "{'val_loss': 0.4595627263188362, 'accuracy': 0.7786697247706422, 'f1': 0.8149568552253116}\n",
      "\n",
      "Epoch 3\n",
      "train_loss: 0.38090297276092366\n",
      "{'val_loss': 0.35970193839498926, 'accuracy': 0.8509174311926605, 'f1': 0.865979381443299}\n",
      "\n",
      "Epoch 4\n",
      "train_loss: 0.19470196716946447\n",
      "{'val_loss': 0.4552712818341596, 'accuracy': 0.8291284403669725, 'f1': 0.8484231943031536}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.4552712818341596,\n",
       " 'accuracy': 0.8291284403669725,\n",
       " 'f1': 0.8484231943031536}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final, metrics_final = train_model(\n",
    "    model_name=model_name,\n",
    "    train_dataset=train_tok_final,\n",
    "    val_dataset=val_tok,\n",
    "    epochs=4,\n",
    "    lr=2e-5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "metrics_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e2a4c-c365-4afa-8c88-19c37573736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0011bc0-a7de-4fb4-8732-10b1b0d2616f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abc45e-a2f9-4f77-b0c1-850dae57b373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50fa4a-c51b-4706-ba90-9a8fc86689e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uni-project)",
   "language": "python",
   "name": "uni-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
