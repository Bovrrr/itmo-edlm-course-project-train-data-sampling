{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e57cf57-f5ed-4dc5-85a6-f31aca49c197",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deterministic init done.\n"
     ]
    }
   ],
   "source": [
    "# --- FULL DETERMINISM BLOCK ---\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"FLASH_ATTENTION_USE_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# путь к проекту\n",
    "import sys\n",
    "sys.path.append(\"/home/onbaev.baurzhan/source/project/src\")\n",
    "\n",
    "print(\"Deterministic init done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6a18ac-4ebf-4e62-b3d1-9c0dd108eda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onbaev.baurzhan/source/project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67349, 872)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"glue\", \"sst2\")\n",
    "train_raw = ds[\"train\"]\n",
    "val_raw = ds[\"validation\"]\n",
    "\n",
    "len(train_raw), len(val_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71eaa28-d668-4330-804c-b85d680b662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_10 = train_raw.shuffle(seed=42).select(range(int(0.1 * len(train_raw))))\n",
    "len(train_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c40d65-eba7-458d-8ae5-fe18823e57e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\", trust_remote_code=True)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"sentence\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "    enc[\"label\"] = batch[\"label\"]\n",
    "    return enc\n",
    "\n",
    "train_tok = train_10.map(tokenize_batch, batched=True, remove_columns=train_10.column_names)\n",
    "val_tok   = val_raw.map(tokenize_batch, batched=True, remove_columns=val_raw.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4777972e-df10-4562-ad79-45a6203384d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/onbaev.baurzhan/source/project/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:468.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "train_loss: 0.3929419008511785\n",
      "{'val_loss': 0.22405235016984598, 'accuracy': 0.9059633027522935, 'f1': 0.9076576576576577}\n",
      "\n",
      "Epoch 2\n",
      "train_loss: 0.16062389586950648\n",
      "{'val_loss': 0.22300875539492285, 'accuracy': 0.9208715596330275, 'f1': 0.9198606271777003}\n",
      "\n",
      "Epoch 3\n",
      "train_loss: 0.05928887555682458\n",
      "{'val_loss': 0.3417216074386878, 'accuracy': 0.9139908256880734, 'f1': 0.9146757679180887}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.3417216074386878,\n",
       " 'accuracy': 0.9139908256880734,\n",
       " 'f1': 0.9146757679180887}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_utils import train_model\n",
    "\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "model, metrics = train_model(\n",
    "    model_name=model_name,\n",
    "    train_dataset=train_tok,\n",
    "    val_dataset=val_tok,\n",
    "    epochs=3,\n",
    "    lr=2e-5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f9a99-5b27-4798-af01-455fe734869e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7d4d38-0bb8-495e-9d42-d15d244021f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/random10_scorer/tokenizer_config.json',\n",
       " '../models/random10_scorer/special_tokens_map.json',\n",
       " '../models/random10_scorer/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/random10_scorer\")\n",
    "tokenizer.save_pretrained(\"../models/random10_scorer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519a663-d054-4fe6-986c-7d382edb87ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uni-project)",
   "language": "python",
   "name": "uni-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
